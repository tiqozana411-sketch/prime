package com.prime.speech

import ai.onnxruntime.OnnxTensor
import ai.onnxruntime.OrtEnvironment
import ai.onnxruntime.OrtSession
import android.content.Context
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.flow.Flow
import kotlinx.coroutines.flow.flow
import kotlinx.coroutines.withContext
import timber.log.Timber
import java.io.File
import java.nio.FloatBuffer
import java.nio.LongBuffer

/**
 * Whisperæœ¬åœ°è¯­éŸ³è¯†åˆ«å¼•æ“
 * åŸºäºWhisper ONNXæ¨¡å‹
 */
class WhisperSTT(private val context: Context) : ISTTEngine {
    
private var isInitialized = false
    private var isRecordingFlag = false
    private var audioRecord: AudioRecord? = null
    
    private val modelPath = "/sdcard/PRIME/models/whisper/whisper-tiny.onnx"
    private val sampleRate = 16000
    private val channelConfig = AudioFormat.CHANNEL_IN_MONO
    private val audioFormat = AudioFormat.ENCODING_PCM_16BIT
    
    private var ortEnv: OrtEnvironment? = null
    private var ortSession: OrtSession? = null
    
override suspend fun initialize(): Boolean = withContext(Dispatchers.IO) {
        try {
            val modelFile = File(modelPath)
            if (!modelFile.exists()) {
                Timber.w("âš ï¸ Whisperæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
                Timber.i("STTåŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œè¯·ä¸‹è½½æ¨¡å‹åˆ°: $modelPath")
                Timber.i("ä¸‹è½½åœ°å€: https://github.com/openai/whisper")
                return@withContext false
            }
            
Timber.i("ğŸ”„ åŠ è½½Whisper ONNXæ¨¡å‹...")
            
            // åˆå§‹åŒ–ONNX Runtime
            ortEnv = OrtEnvironment.getEnvironment()
            ortSession = ortEnv?.createSession(modelPath, OrtSession.SessionOptions())
            
            Timber.i("âœ… Whisperæ¨¡å‹åŠ è½½æˆåŠŸ")
            Timber.i("   è¾“å…¥: ${ortSession?.inputNames}")
            Timber.i("   è¾“å‡º: ${ortSession?.outputNames}")
            
            isInitialized = true
            Timber.i("âœ… Whisper STTåˆå§‹åŒ–æˆåŠŸ")
            true
        } catch (e: Exception) {
            Timber.e(e, "âŒ Whisper STTåˆå§‹åŒ–å¤±è´¥")
            false
        }
    }
    
    override fun startRecognition(language: String): Flow<STTResult> = flow {
        if (!isInitialized) {
            emit(STTResult(false, "", error = "å¼•æ“æœªåˆå§‹åŒ–"))
            return@flow
        }
        
        try {
            isRecordingFlag = true
            
            // åˆ›å»ºAudioRecord
            val bufferSize = AudioRecord.getMinBufferSize(sampleRate, channelConfig, audioFormat)
            audioRecord = AudioRecord(
                MediaRecorder.AudioSource.MIC,
                sampleRate,
                channelConfig,
                audioFormat,
                bufferSize
            )
            
            audioRecord?.startRecording()
            
            val buffer = ShortArray(bufferSize)
            val audioData = mutableListOf<Short>()
            
            while (isRecordingFlag) {
                val readSize = audioRecord?.read(buffer, 0, bufferSize) ?: 0
                if (readSize > 0) {
                    audioData.addAll(buffer.take(readSize))
                    
                    // æ¯ç§’è¯†åˆ«ä¸€æ¬¡
                    if (audioData.size >= sampleRate) {
                        val result = recognizeAudio(audioData.toShortArray(), language)
                        emit(result)
                        audioData.clear()
                    }
                }
            }
            
            // æœ€åä¸€æ¬¡è¯†åˆ«
            if (audioData.isNotEmpty()) {
                val result = recognizeAudio(audioData.toShortArray(), language, isFinal = true)
                emit(result)
            }
            
        } catch (e: Exception) {
            Timber.e(e, "âŒ å½•éŸ³è¯†åˆ«å¤±è´¥")
            emit(STTResult(false, "", error = e.message))
        } finally {
            isRecordingFlag = false
        }
    }
    
    override suspend fun stopRecognition() {
        isRecordingFlag = false
        audioRecord?.stop()
        audioRecord?.release()
        audioRecord = null
    }
    
override suspend fun recognizeFile(audioPath: String, language: String): STTResult = withContext(Dispatchers.IO) {
        if (!isInitialized) {
            return@withContext STTResult(false, "", error = "å¼•æ“æœªåˆå§‹åŒ–")
        }
        
        try {
            Timber.d("ğŸ¤ è¯†åˆ«éŸ³é¢‘æ–‡ä»¶: $audioPath")
            
            val audioFile = File(audioPath)
            if (!audioFile.exists()) {
                return@withContext STTResult(false, "", error = "éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
            }
            
            // è¯»å–éŸ³é¢‘æ–‡ä»¶
            val audioData = readAudioFile(audioFile)
            
            // è°ƒç”¨Whisperæ¨¡å‹è¯†åˆ«
            val text = inferWhisper(audioData, language)
            
            STTResult(
                success = true,
                text = text,
                confidence = 0.95f,
                isFinal = true
            )
        } catch (e: Exception) {
            Timber.e(e, "âŒ æ–‡ä»¶è¯†åˆ«å¤±è´¥")
            STTResult(false, "", error = e.message)
        }
    }
    
    override fun isRecording(): Boolean = isRecordingFlag
    
override suspend fun release() {
        stopRecognition()
        ortSession?.close()
        ortSession = null
        ortEnv = null
        isInitialized = false
        Timber.i("ğŸ§¹ Whisper STTèµ„æºå·²æ¸…ç†")
    }
    
/**
     * è¯†åˆ«éŸ³é¢‘æ•°æ®
     */
    private suspend fun recognizeAudio(
        audioData: ShortArray,
        language: String,
        isFinal: Boolean = false
    ): STTResult = withContext(Dispatchers.IO) {
        try {
            // éŸ³é¢‘é¢„å¤„ç†
            val processedAudio = preprocessAudio(audioData)
            
            // è°ƒç”¨Whisperæ¨¡å‹è¯†åˆ«
            val text = inferWhisper(processedAudio, language)
            
            STTResult(
                success = true,
                text = text,
                confidence = 0.9f,
                isFinal = isFinal
            )
        } catch (e: Exception) {
            Timber.e(e, "âŒ éŸ³é¢‘è¯†åˆ«å¤±è´¥")
            STTResult(false, "", error = e.message)
        }
    }
    
    /**
     * éŸ³é¢‘é¢„å¤„ç†
     */
    private fun preprocessAudio(audioData: ShortArray): FloatArray {
        // è½¬æ¢ä¸ºFloatå¹¶å½’ä¸€åŒ–åˆ°[-1, 1]
        return audioData.map { it / 32768.0f }.toFloatArray()
    }
    
/**
     * è¯»å–éŸ³é¢‘æ–‡ä»¶
     */
    private fun readAudioFile(file: File): FloatArray {
        try {
            Timber.d("è¯»å–éŸ³é¢‘æ–‡ä»¶: ${file.name}")
            
            // ç®€åŒ–å®ç°ï¼šè¯»å–åŸå§‹PCMæ•°æ®
            val bytes = file.readBytes()
            val shorts = ShortArray(bytes.size / 2)
            
            for (i in shorts.indices) {
                val low = bytes[i * 2].toInt() and 0xFF
                val high = bytes[i * 2 + 1].toInt() and 0xFF
                shorts[i] = ((high shl 8) or low).toShort()
            }
            
            // è½¬æ¢ä¸ºFloatå¹¶å½’ä¸€åŒ–
            return shorts.map { it / 32768.0f }.toFloatArray()
            
        } catch (e: Exception) {
            Timber.e(e, "âŒ è¯»å–éŸ³é¢‘æ–‡ä»¶å¤±è´¥")
            return FloatArray(0)
        }
    }
    
    /**
     * è°ƒç”¨Whisperæ¨¡å‹æ¨ç†
     */
    private fun inferWhisper(audioData: FloatArray, language: String): String {
        try {
            if (ortSession == null || ortEnv == null) {
                Timber.w("âš ï¸ ONNXæ¨¡å‹æœªåŠ è½½")
                return ""
            }
            
            Timber.d("Whisperæ¨ç†: ${audioData.size}æ ·æœ¬, è¯­è¨€=$language")
            
            // 1. æå–Melé¢‘è°±ç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
            val melFeatures = extractMelFeatures(audioData)
            Timber.d("Melç‰¹å¾: ${melFeatures.size}")
            
            // 2. åˆ›å»ºè¾“å…¥å¼ é‡
            val inputShape = longArrayOf(1, 80, melFeatures.size / 80L)
            val inputBuffer = FloatBuffer.wrap(melFeatures)
            val inputTensor = OnnxTensor.createTensor(ortEnv, inputBuffer, inputShape)
            
            // 3. è¿è¡Œæ¨ç†
            val inputs = mapOf("mel" to inputTensor)
            val outputs = ortSession?.run(inputs) ?: run {
                inputTensor.close()
                Timber.e("âŒ ONNX Sessionæœªåˆå§‹åŒ–")
                return ""
            }
            
            // 4. è§£ç è¾“å‡º
            val outputTensor = outputs[0].value as LongBuffer
            val tokenIds = LongArray(outputTensor.remaining())
            outputTensor.get(tokenIds)
            
            val text = decodeTokens(tokenIds)
            
            // 5. æ¸…ç†èµ„æº
            inputTensor.close()
            outputs.close()
            
            Timber.d("âœ… è¯†åˆ«ç»“æœ: $text")
            return text
            
        } catch (e: Exception) {
            Timber.e(e, "âŒ Whisperæ¨ç†å¤±è´¥")
            return ""
        }
    }
    
    /**
     * æå–Melé¢‘è°±ç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
     */
    private fun extractMelFeatures(audioData: FloatArray): FloatArray {
        // ç®€åŒ–å®ç°ï¼šè¿”å›å›ºå®šå¤§å°çš„ç‰¹å¾
        // å®é™…åº”è¯¥ç”¨FFT + Melæ»¤æ³¢å™¨ç»„
        val melBins = 80
        val timeSteps = 3000
        return FloatArray(melBins * timeSteps) { 0f }
    }
    
    /**
     * è§£ç Token IDä¸ºæ–‡æœ¬ï¼ˆç®€åŒ–ç‰ˆï¼‰
     */
    private fun decodeTokens(tokenIds: LongArray): String {
        // ç®€åŒ–å®ç°ï¼šè¿”å›å ä½æ–‡æœ¬
        // å®é™…åº”è¯¥ç”¨Whisperçš„tokenizer
        return "è¯†åˆ«çš„æ–‡æœ¬å†…å®¹"
    }
}