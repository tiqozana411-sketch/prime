package com.prime.speech

import ai.onnxruntime.OnnxTensor
import ai.onnxruntime.OrtEnvironment
import ai.onnxruntime.OrtSession
import android.content.Context
import android.media.AudioAttributes
import android.media.AudioFormat
import android.media.AudioTrack
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.withContext
import timber.log.Timber
import java.io.File
import java.nio.FloatBuffer
import java.nio.LongBuffer

/**
 * Piperæœ¬åœ°TTSå¼•æ“
 * åŸºäºPiper ONNXæ¨¡å‹
 */
class PiperTTS(private val context: Context) : ITTSEngine {
    
private var isInitialized = false
    private var isSpeakingFlag = false
    private var audioTrack: AudioTrack? = null
    
    private val modelPath = "/sdcard/PRIME/models/piper/zh_CN-huayan-medium.onnx"
    private val configPath = "/sdcard/PRIME/models/piper/zh_CN-huayan-medium.onnx.json"
    
    private var ortEnv: OrtEnvironment? = null
    private var ortSession: OrtSession? = null
    
    override suspend fun initialize(): Boolean = withContext(Dispatchers.IO) {
        try {
            // æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
            val modelFile = File(modelPath)
            val configFile = File(configPath)
            
if (!modelFile.exists() || !configFile.exists()) {
                Timber.w("âš ï¸ Piperæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
                Timber.i("TTSåŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œè¯·ä¸‹è½½æ¨¡å‹åˆ°: $modelPath")
                Timber.i("ä¸‹è½½åœ°å€: https://github.com/rhasspy/piper/releases")
                return@withContext false
            }
            
Timber.i("ğŸ”„ åŠ è½½Piper ONNXæ¨¡å‹...")
            
            // åˆå§‹åŒ–ONNX Runtime
            ortEnv = OrtEnvironment.getEnvironment()
            ortSession = ortEnv?.createSession(modelPath, OrtSession.SessionOptions())
            
            Timber.i("âœ… Piperæ¨¡å‹åŠ è½½æˆåŠŸ")
            Timber.i("   è¾“å…¥: ${ortSession?.inputNames}")
            Timber.i("   è¾“å‡º: ${ortSession?.outputNames}")
            
            isInitialized = true
            Timber.i("âœ… Piper TTSåˆå§‹åŒ–æˆåŠŸ")
            true
        } catch (e: Exception) {
            Timber.e(e, "âŒ Piper TTSåˆå§‹åŒ–å¤±è´¥")
            false
        }
    }
    
    override suspend fun speak(
        text: String,
        language: String,
        speed: Float,
        pitch: Float
    ): Boolean = withContext(Dispatchers.IO) {
        if (!isInitialized) {
            Timber.w("âš ï¸ TTSå¼•æ“æœªåˆå§‹åŒ–")
            return@withContext false
        }
        
try {
            isSpeakingFlag = true
            Timber.d("ğŸ”Š å¼€å§‹æœ—è¯»: $text")
            
            // æ–‡æœ¬é¢„å¤„ç†
            val processedText = preprocessText(text)
            
            // è°ƒç”¨Piperæ¨¡å‹ç”ŸæˆéŸ³é¢‘
            val audioData = generateAudio(processedText, speed, pitch)
            
            if (audioData.isEmpty()) {
                Timber.w("âš ï¸ éŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é™éŸ³å ä½")
                isSpeakingFlag = false
                return@withContext false
            }
            
            // æ’­æ”¾éŸ³é¢‘
            playAudio(audioData)
            
            isSpeakingFlag = false
            Timber.i("âœ… TTSæœ—è¯»å®Œæˆ")
            true
        } catch (e: Exception) {
            isSpeakingFlag = false
            Timber.e(e, "âŒ TTSæœ—è¯»å¤±è´¥")
            false
        }
    }
    
    override suspend fun stop() {
        audioTrack?.stop()
        audioTrack?.release()
        audioTrack = null
        isSpeakingFlag = false
    }
    
    override suspend fun pause() {
        audioTrack?.pause()
    }
    
    override suspend fun resume() {
        audioTrack?.play()
    }
    
    override fun isSpeaking(): Boolean = isSpeakingFlag
    
override suspend fun release() {
        stop()
        ortSession?.close()
        ortSession = null
        ortEnv = null
        isInitialized = false
        Timber.i("ğŸ§¹ Piper TTSèµ„æºå·²æ¸…ç†")
    }
    
/**
     * ç”ŸæˆéŸ³é¢‘æ•°æ®ï¼ˆä½¿ç”¨ONNX Runtimeæ¨ç†ï¼‰
     */
    private fun generateAudio(text: String, speed: Float, pitch: Float): ByteArray {
        try {
            if (ortSession == null || ortEnv == null) {
                Timber.w("âš ï¸ ONNXæ¨¡å‹æœªåŠ è½½")
                return ByteArray(0)
            }
            
            Timber.d("ç”ŸæˆéŸ³é¢‘: $text (speed=$speed, pitch=$pitch)")
            
            // 1. æ–‡æœ¬è½¬éŸ³ç´ IDï¼ˆç®€åŒ–ç‰ˆï¼‰
            val phonemeIds = textToPhonemes(text)
            Timber.d("éŸ³ç´ æ•°é‡: ${phonemeIds.size}")
            
            // 2. åˆ›å»ºè¾“å…¥å¼ é‡
            val inputShape = longArrayOf(1, phonemeIds.size.toLong())
            val inputBuffer = LongBuffer.wrap(phonemeIds.map { it.toLong() }.toLongArray())
            val inputTensor = OnnxTensor.createTensor(ortEnv, inputBuffer, inputShape)
            
            // 3. è¿è¡Œæ¨ç†
            val inputs = mapOf("input" to inputTensor)
            val outputs = ortSession?.run(inputs) ?: run {
                inputTensor.close()
                Timber.e("âŒ ONNX Sessionæœªåˆå§‹åŒ–")
                return ByteArray(0)
            }
            
            // 4. æå–éŸ³é¢‘æ•°æ®
            val outputTensor = outputs[0].value as FloatBuffer
            val audioFloats = FloatArray(outputTensor.remaining())
            outputTensor.get(audioFloats)
            
            // 5. è½¬æ¢ä¸ºPCM 16bit
            val audioBytes = floatToPCM16(audioFloats)
            
            // 6. æ¸…ç†èµ„æº
            inputTensor.close()
            outputs.close()
            
            Timber.d("âœ… éŸ³é¢‘ç”Ÿæˆå®Œæˆ: ${audioBytes.size} bytes")
            return audioBytes
            
        } catch (e: Exception) {
            Timber.e(e, "âŒ éŸ³é¢‘ç”Ÿæˆå¤±è´¥")
            return ByteArray(0)
        }
    }
    
    /**
     * æ–‡æœ¬è½¬éŸ³ç´ ï¼ˆç®€åŒ–ç‰ˆï¼‰
     */
    private fun textToPhonemes(text: String): List<Int> {
        // ç®€åŒ–å®ç°ï¼šæ¯ä¸ªå­—ç¬¦æ˜ å°„åˆ°ID
        // å®é™…åº”è¯¥ç”¨ä¸“ä¸šçš„ä¸­æ–‡åˆ†è¯+éŸ³ç´ è½¬æ¢
        return text.map { it.code % 256 }
    }
    
    /**
     * FloatéŸ³é¢‘è½¬PCM 16bit
     */
    private fun floatToPCM16(floats: FloatArray): ByteArray {
        val bytes = ByteArray(floats.size * 2)
        for (i in floats.indices) {
            val sample = (floats[i] * 32767f).toInt().coerceIn(-32768, 32767)
            bytes[i * 2] = (sample and 0xFF).toByte()
            bytes[i * 2 + 1] = ((sample shr 8) and 0xFF).toByte()
        }
        return bytes
    }
    
    /**
     * æ–‡æœ¬é¢„å¤„ç†
     */
    private fun preprocessText(text: String): String {
        return text
            .replace(Regex("\\s+"), " ")
            .trim()
    }
    
    /**
     * æ’­æ”¾éŸ³é¢‘
     */
    private fun playAudio(audioData: ByteArray) {
        val sampleRate = 22050
        val channelConfig = AudioFormat.CHANNEL_OUT_MONO
        val audioFormat = AudioFormat.ENCODING_PCM_16BIT
        
        val bufferSize = AudioTrack.getMinBufferSize(sampleRate, channelConfig, audioFormat)
        
        audioTrack = AudioTrack.Builder()
            .setAudioAttributes(
                AudioAttributes.Builder()
                    .setUsage(AudioAttributes.USAGE_MEDIA)
                    .setContentType(AudioAttributes.CONTENT_TYPE_SPEECH)
                    .build()
            )
            .setAudioFormat(
                AudioFormat.Builder()
                    .setSampleRate(sampleRate)
                    .setChannelMask(channelConfig)
                    .setEncoding(audioFormat)
                    .build()
            )
            .setBufferSizeInBytes(bufferSize)
            .build()
        
        audioTrack?.play()
        audioTrack?.write(audioData, 0, audioData.size)
    }
}