package com.prime.speech

import android.content.Context
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.telecom.Call
import android.telecom.InCallService
import kotlinx.coroutines.*
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import timber.log.Timber
import java.io.File
import java.io.FileOutputStream

/**
 * é€šè¯éŸ³é¢‘æ‹¦æˆªå™¨
 * æ‹¦æˆªQQ/å¾®ä¿¡/ç”µè¯çš„é€šè¯éŸ³é¢‘ï¼Œå®æ—¶è¯†åˆ«è¯­éŸ³æŒ‡ä»¤
 */
class CallAudioInterceptor(
    private val context: Context,
    private val sttEngine: ISTTEngine,
    private val onCommandReceived: (VoiceCommand) -> Unit
) {
    
    private var audioRecord: AudioRecord? = null
    private var isRecording = false
    private var recordingJob: Job? = null
    
    private val _callState = MutableStateFlow<CallState>(CallState.Idle)
    val callState: StateFlow<CallState> = _callState
    
    // éŸ³é¢‘å‚æ•°
    private val sampleRate = 16000
    private val channelConfig = AudioFormat.CHANNEL_IN_MONO
    private val audioFormat = AudioFormat.ENCODING_PCM_16BIT
    
    // éŸ³é¢‘ç¼“å†²åŒº
    private val audioBuffer = mutableListOf<Short>()
    private val bufferDuration = 3000 // 3ç§’ç¼“å†²
    
    /**
     * å¼€å§‹æ‹¦æˆªé€šè¯éŸ³é¢‘
     */
    fun startIntercepting(callType: CallType) {
        if (isRecording) {
            Timber.w("âš ï¸ å·²åœ¨æ‹¦æˆªé€šè¯éŸ³é¢‘")
            return
        }
        
        _callState.value = CallState.Active(callType)
        
        try {
            val bufferSize = AudioRecord.getMinBufferSize(sampleRate, channelConfig, audioFormat)
            
            // ä½¿ç”¨VOICE_COMMUNICATIONéŸ³é¢‘æºï¼ˆé€šè¯éŸ³é¢‘ï¼‰
            audioRecord = AudioRecord(
                MediaRecorder.AudioSource.VOICE_COMMUNICATION,
                sampleRate,
                channelConfig,
                audioFormat,
                bufferSize * 2
            )
            
            if (audioRecord?.state != AudioRecord.STATE_INITIALIZED) {
                Timber.e("âŒ AudioRecordåˆå§‹åŒ–å¤±è´¥")
                return
            }
            
            audioRecord?.startRecording()
            isRecording = true
            
            Timber.i("âœ… å¼€å§‹æ‹¦æˆª${callType.name}é€šè¯éŸ³é¢‘")
            
            // å¯åŠ¨å½•éŸ³åç¨‹
            recordingJob = CoroutineScope(Dispatchers.IO).launch {
                processAudioStream(bufferSize)
            }
            
        } catch (e: Exception) {
            Timber.e(e, "âŒ å¯åŠ¨éŸ³é¢‘æ‹¦æˆªå¤±è´¥")
            _callState.value = CallState.Error(e.message ?: "æœªçŸ¥é”™è¯¯")
        }
    }
    
    /**
     * åœæ­¢æ‹¦æˆª
     */
    fun stopIntercepting() {
        isRecording = false
        recordingJob?.cancel()
        
        audioRecord?.stop()
        audioRecord?.release()
        audioRecord = null
        
        audioBuffer.clear()
        _callState.value = CallState.Idle
        
        Timber.i("ğŸ›‘ åœæ­¢æ‹¦æˆªé€šè¯éŸ³é¢‘")
    }
    
    /**
     * å¤„ç†éŸ³é¢‘æµ
     */
    private suspend fun processAudioStream(bufferSize: Int) {
        val buffer = ShortArray(bufferSize)
        
        while (isRecording) {
            try {
                val readSize = audioRecord?.read(buffer, 0, bufferSize) ?: 0
                
                if (readSize > 0) {
                    // æ·»åŠ åˆ°ç¼“å†²åŒº
                    audioBuffer.addAll(buffer.take(readSize))
                    
                    // æ¯3ç§’è¯†åˆ«ä¸€æ¬¡
                    if (audioBuffer.size >= sampleRate * bufferDuration / 1000) {
                        processAudioBuffer()
                    }
                }
                
            } catch (e: Exception) {
                Timber.e(e, "âŒ éŸ³é¢‘æµå¤„ç†é”™è¯¯")
                delay(100)
            }
        }
    }
    
    /**
     * å¤„ç†éŸ³é¢‘ç¼“å†²åŒº
     */
    private suspend fun processAudioBuffer() {
        if (audioBuffer.isEmpty()) return
        
        try {
            // ä¿å­˜éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            val tempFile = File(context.cacheDir, "call_audio_${System.currentTimeMillis()}.pcm")
            saveAudioToFile(audioBuffer.toShortArray(), tempFile)
            
            // è°ƒç”¨STTè¯†åˆ«
            val result = sttEngine.recognizeFile(tempFile.absolutePath, "zh-CN")
            
            if (result?.success == true && result.text.isNotBlank()) {
                Timber.i("ğŸ¤ è¯†åˆ«åˆ°é€šè¯è¯­éŸ³: ${result.text}")
                
                // è§£æä¸ºæŒ‡ä»¤
                val command = VoiceCommandParser.parse(result.text)
                if (command != null) {
                    Timber.i("âœ… è§£æåˆ°æŒ‡ä»¤: $command")
                    onCommandReceived(command)
                }
            }
            
            // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            tempFile.delete()
            
        } catch (e: Exception) {
            Timber.e(e, "âŒ éŸ³é¢‘ç¼“å†²åŒºå¤„ç†å¤±è´¥")
        } finally {
            audioBuffer.clear()
        }
    }
    
    /**
     * ä¿å­˜éŸ³é¢‘åˆ°æ–‡ä»¶
     */
    private fun saveAudioToFile(audioData: ShortArray, file: File) {
        FileOutputStream(file).use { fos ->
            audioData.forEach { sample ->
                fos.write(sample.toInt() and 0xFF)
                fos.write((sample.toInt() shr 8) and 0xFF)
            }
        }
    }
}

/**
 * é€šè¯çŠ¶æ€
 */
sealed class CallState {
    object Idle : CallState()
    data class Active(val type: CallType) : CallState()
    data class Error(val message: String) : CallState()
}

/**
 * é€šè¯ç±»å‹
 */
enum class CallType {
    PHONE,      // ç”µè¯
    WECHAT,     // å¾®ä¿¡
    QQ,         // QQ
    OTHER       // å…¶ä»–
}